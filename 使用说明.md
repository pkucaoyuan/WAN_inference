# WAN2.2-5B 模型使用说明

## 概述
这是WAN2.2-5B（Text-to-Image-to-Video）模型的代码仓库。此仓库**仅包含模型代码和配置文件**，不包含模型权重，以避免本地存储和运行大型模型。

## 目录结构
```
Wan2.2-TI2V-5B/
├── README.md                          # 官方说明文档
├── config.json                        # 模型配置文件
├── configuration.json                 # 配置信息
├── diffusion_pytorch_model.safetensors.index.json  # 权重索引文件
├── download_model_weights.py          # Python下载脚本
├── download_model_weights.bat         # Windows批处理下载脚本
├── 使用说明.md                        # 本文档
├── assets/                            # 资源文件夹
├── examples/                          # 示例文件
└── google/umt5-xxl/                   # T5编码器配置
```

## 下载模型权重

### 方法一：使用Python脚本（推荐）
```bash
python download_model_weights.py
```

### 方法二：使用Windows批处理脚本
```bash
download_model_weights.bat
```

### 方法三：手动使用Hugging Face CLI
```bash
# 安装依赖
pip install huggingface_hub[cli]

# 下载到指定目录
huggingface-cli download Wan-AI/Wan2.2-TI2V-5B --local-dir ./model_weights
```

### 方法四：使用Git LFS（如果在仓库目录中）
```bash
# 安装Git LFS
git lfs install

# 拉取LFS文件
git lfs pull
```

## 重要注意事项

### ⚠️ 本地运行限制
- **严禁在本地运行此模型**
- 模型文件非常大（约10GB+）
- 需要大量GPU内存和计算资源
- 建议仅在远程服务器或云平台上运行

### 🌐 推荐的远程运行平台
1. **启智算力平台** - 提供模型训练和推理云服务
2. **共绩算力** - 支持容器化部署，提供GPU资源
3. **Google Colab Pro** - 适合实验和测试
4. **AWS/Azure/GCP** - 企业级云计算平台

### 📋 系统要求（仅供参考，请勿本地运行）
- GPU: NVIDIA RTX 4090 或更高（24GB+ VRAM）
- RAM: 32GB+
- 存储: 50GB+ 可用空间
- CUDA: 11.8+
- Python: 3.8+

## 模型信息
- **模型名称**: WAN2.2-TI2V-5B
- **模型类型**: Text-to-Image-to-Video 生成模型
- **参数数量**: 50亿
- **输入**: 文本描述
- **输出**: 图像序列/视频

## 许可证
请参考原始仓库的许可证文件。

## 🚀 推理加速技巧

### **CFG截断优化（新功能）**
WAN2.2现在支持CFG截断技术，可以在最后几步跳过条件前传来加速推理：

**⚠️ 重要更新**: CFG截断现在**默认禁用**（cfg_truncate_steps=0），需要手动启用。

```bash
# 启用CFG截断（手动开启）
python generate.py --task ti2v-5B \
    --ckpt_dir ./model_weights \
    --cfg_truncate_steps 5 \
    --prompt "Your prompt here"

# 27B MOE模型双重CFG截断
python generate.py --task t2v-A14B \
    --ckpt_dir ./model_weights \
    --cfg_truncate_steps 5 \
    --cfg_truncate_high_noise_steps 3 \
    --prompt "Your prompt here"
```

### **时间记录功能（新增）**
现在推理会自动记录详细的时间信息：
- ⏱️ **模型加载耗时**: 包含所有模型组件的加载时间
- ⚡ **纯推理耗时**: 不包含模型加载的实际推理时间  
- 🔄 **专家切换耗时**: MOE模型专家切换的时间开销
- 📈 **推理效率**: 帧/秒的生成速度

### **帧数自动修正功能**
如果设置了无效的frame_num，会自动修正：
- `frame_num=1` → 自动改为 `frame_num=5`
- 其他无效值 → 自动修正到最近的4n+1值

### **双重CFG截断参数说明**
**低噪声专家截断（最后几步）**：
- `--cfg_truncate_steps 3`: 激进加速，轻微质量损失
- `--cfg_truncate_steps 5`: 平衡模式（推荐）
- `--cfg_truncate_steps 8`: 保守加速，质量优先  
- `--cfg_truncate_steps 0`: 禁用低噪声截断

**高噪声专家截断（专家切换前）**：
- `--cfg_truncate_high_noise_steps 2`: 轻微加速
- `--cfg_truncate_high_noise_steps 3`: 平衡模式（推荐）
- `--cfg_truncate_high_noise_steps 5`: 激进加速
- `--cfg_truncate_high_noise_steps 0`: 禁用高噪声截断

### **组合使用示例**
```bash
# 双重CFG截断（最大加速）
python generate.py --task t2v-A14B \
    --cfg_truncate_steps 5 \
    --cfg_truncate_high_noise_steps 3 \
    --prompt "Your prompt"

# 只截断高噪声专家
python generate.py --task t2v-A14B \
    --cfg_truncate_steps 0 \
    --cfg_truncate_high_noise_steps 3 \
    --prompt "Your prompt"
```

### **性能提升**
- **单独低噪声截断**: 20-30%时间减少
- **单独高噪声截断**: 15-25%时间减少  
- **双重截断**: 35-50%时间减少
- **质量影响**: 最小，主要在细节层面
- **适用场景**: 所有WAN2.2 MOE模型（27B）

## 技术支持
如有问题，请参考：
1. 官方README.md文档
2. Hugging Face模型页面: https://huggingface.co/Wan-AI/Wan2.2-TI2V-5B
3. 相关技术论文和文档

---
**再次提醒：此仓库仅用于代码研究，请勿在本地运行模型！**

