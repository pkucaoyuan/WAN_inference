#!/usr/bin/env python3
"""
CFGæˆªæ–­æ–¹æ³• vs Baseline å¯¹æ¯”è„šæœ¬
æ¯”è¾ƒä¸¤ç§æ–¹æ³•çš„æœ€ç»ˆç”Ÿæˆç»“æœè¯¯å·®
"""

import os
import sys
import argparse
import torch
import numpy as np
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import wan
from wan.configs import SIZE_CONFIGS, WAN_CONFIGS


def load_model(ckpt_dir, device, task="t2v-A14B"):
    """åŠ è½½æ¨¡å‹"""
    print("ğŸ”„ åŠ è½½æ¨¡å‹...")
    
    # è·å–é…ç½®
    cfg = WAN_CONFIGS[task]
    
    # åˆ›å»ºWanT2Vå®ä¾‹
    model = wan.WanT2V(
        config=cfg,
        checkpoint_dir=ckpt_dir,
        device_id=int(device.split(':')[-1]) if ':' in device else 0,
        rank=0,
        t5_fsdp=False,
        dit_fsdp=False,
        use_sp=False,
        t5_cpu=False,
        init_on_cpu=True,
        convert_model_dtype=False,
    )
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    return model


def generate_video(model, prompt, size, frame_num, sample_steps, 
                  cfg_truncate_steps, cfg_truncate_high_noise_steps, 
                  seed, output_dir, method_name, enable_half_frame_generation=False,
                  enable_improved_frame_completion=False):
    """ç”Ÿæˆè§†é¢‘å¹¶è¿”å›ç»“æœ"""
    print(f"\nğŸ¬ å¼€å§‹ç”Ÿæˆ ({method_name})...")
    print(f"ğŸ“ æç¤ºè¯: {prompt}")
    print(f"ğŸ“ å°ºå¯¸: {size}")
    print(f"ğŸï¸ å¸§æ•°: {frame_num}")
    print(f"ğŸ”„ é‡‡æ ·æ­¥æ•°: {sample_steps}")
    print(f"âš™ï¸ CFGæˆªæ–­æ­¥æ•°: {cfg_truncate_steps}")
    print(f"âš™ï¸ é«˜å™ªå£°CFGæˆªæ–­æ­¥æ•°: {cfg_truncate_high_noise_steps}")
    print(f"ğŸï¸ å¸§æ•°å‡åŠä¼˜åŒ–: {enable_half_frame_generation}")
    print(f"ğŸ”„ æ”¹è¿›å¸§æ•°è¡¥å…¨: {enable_improved_frame_completion}")
    print(f"ğŸ² ç§å­: {seed}")
    
    # è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    
    # ç”Ÿæˆè§†é¢‘
    video, timing_info = model.generate(
        input_prompt=prompt,
        size=size,
        frame_num=frame_num,
        sampling_steps=sample_steps,
        cfg_truncate_steps=cfg_truncate_steps,
        cfg_truncate_high_noise_steps=cfg_truncate_high_noise_steps,
        output_dir=output_dir,
        seed=seed,
        enable_half_frame_generation=enable_half_frame_generation,
        enable_improved_frame_completion=enable_improved_frame_completion
    )
    
    result = {'video': video}
    
    print(f"âœ… {method_name} ç”Ÿæˆå®Œæˆ")
    return result


def calculate_error(result1, result2, method1_name, method2_name):
    """è®¡ç®—ä¸¤ç§æ–¹æ³•çš„è¯¯å·®"""
    print(f"\nğŸ“Š è®¡ç®— {method1_name} vs {method2_name} çš„è¯¯å·®...")
    
    # è·å–ç”Ÿæˆçš„è§†é¢‘æ•°æ®
    video1 = result1['video']  # [B, C, T, H, W]
    video2 = result2['video']  # [B, C, T, H, W]
    
    # ç¡®ä¿ä¸¤ä¸ªè§†é¢‘å½¢çŠ¶ç›¸åŒ
    if video1.shape != video2.shape:
        print(f"âš ï¸ è­¦å‘Š: è§†é¢‘å½¢çŠ¶ä¸åŒ¹é…")
        print(f"   {method1_name}: {video1.shape}")
        print(f"   {method2_name}: {video2.shape}")
        
        # å–æœ€å°å°ºå¯¸
        min_shape = tuple(min(s1, s2) for s1, s2 in zip(video1.shape, video2.shape))
        video1 = video1[tuple(slice(0, s) for s in min_shape)]
        video2 = video2[tuple(slice(0, s) for s in min_shape)]
        print(f"   è°ƒæ•´åå½¢çŠ¶: {video1.shape}")
    
    # è½¬æ¢ä¸ºfloat32è¿›è¡Œè®¡ç®—
    video1 = video1.float()
    video2 = video2.float()
    
    # è®¡ç®—ç»å¯¹è¯¯å·®
    absolute_error = torch.abs(video1 - video2)
    abs_error_mean = absolute_error.mean().item()
    abs_error_max = absolute_error.max().item()
    abs_error_std = absolute_error.std().item()
    
    # è®¡ç®—ç›¸å¯¹è¯¯å·® (é¿å…é™¤é›¶)
    epsilon = 1e-8
    relative_error = absolute_error / (torch.abs(video2) + epsilon)
    rel_error_mean = relative_error.mean().item()
    rel_error_max = relative_error.max().item()
    rel_error_std = relative_error.std().item()
    
    # è®¡ç®—MSEå’ŒPSNR
    mse = torch.mean((video1 - video2) ** 2).item()
    if mse > 0:
        psnr = 20 * torch.log10(1.0 / torch.sqrt(torch.tensor(mse))).item()
    else:
        psnr = float('inf')
    
    # è®¡ç®—SSIM (ç®€åŒ–ç‰ˆæœ¬)
    def ssim_simple(x, y):
        """ç®€åŒ–çš„SSIMè®¡ç®—"""
        mu1 = x.mean()
        mu2 = y.mean()
        sigma1 = x.var()
        sigma2 = y.var()
        sigma12 = ((x - mu1) * (y - mu2)).mean()
        
        c1 = 0.01 ** 2
        c2 = 0.03 ** 2
        
        ssim = ((2 * mu1 * mu2 + c1) * (2 * sigma12 + c2)) / \
               ((mu1 ** 2 + mu2 ** 2 + c1) * (sigma1 + sigma2 + c2))
        return ssim.item()
    
    ssim_value = ssim_simple(video1, video2)
    
    return {
        'absolute_error': {
            'mean': abs_error_mean,
            'max': abs_error_max,
            'std': abs_error_std
        },
        'relative_error': {
            'mean': rel_error_mean,
            'max': rel_error_max,
            'std': rel_error_std
        },
        'mse': mse,
        'psnr': psnr,
        'ssim': ssim_value
    }


def print_error_report(error_stats, method1_name, method2_name):
    """æ‰“å°è¯¯å·®æŠ¥å‘Š"""
    print(f"\n" + "="*80)
    print(f"ğŸ“Š {method1_name} vs {method2_name} è¯¯å·®åˆ†ææŠ¥å‘Š")
    print(f"="*80)
    
    print(f"\nğŸ” ç»å¯¹è¯¯å·® (Absolute Error):")
    print(f"   å¹³å‡å€¼: {error_stats['absolute_error']['mean']:.6f}")
    print(f"   æœ€å¤§å€¼: {error_stats['absolute_error']['max']:.6f}")
    print(f"   æ ‡å‡†å·®: {error_stats['absolute_error']['std']:.6f}")
    
    print(f"\nğŸ“ˆ ç›¸å¯¹è¯¯å·® (Relative Error):")
    print(f"   å¹³å‡å€¼: {error_stats['relative_error']['mean']:.6f}")
    print(f"   æœ€å¤§å€¼: {error_stats['relative_error']['max']:.6f}")
    print(f"   æ ‡å‡†å·®: {error_stats['relative_error']['std']:.6f}")
    
    print(f"\nğŸ“ å›¾åƒè´¨é‡æŒ‡æ ‡:")
    print(f"   MSE: {error_stats['mse']:.6f}")
    print(f"   PSNR: {error_stats['psnr']:.2f} dB")
    print(f"   SSIM: {error_stats['ssim']:.6f}")
    
    print(f"\nğŸ’¡ è§£é‡Š:")
    print(f"   - ç»å¯¹è¯¯å·®è¶Šå°ï¼Œä¸¤ç§æ–¹æ³•ç”Ÿæˆçš„ç»“æœè¶Šç›¸ä¼¼")
    print(f"   - ç›¸å¯¹è¯¯å·®è¶Šå°ï¼Œç›¸å¯¹å·®å¼‚è¶Šå°")
    print(f"   - PSNRè¶Šé«˜ï¼Œå›¾åƒè´¨é‡è¶Šå¥½")
    print(f"   - SSIMè¶Šæ¥è¿‘1ï¼Œç»“æ„ç›¸ä¼¼æ€§è¶Šé«˜")
    
    print(f"="*80)


def main():
    parser = argparse.ArgumentParser(description='CFGæˆªæ–­æ–¹æ³• vs Baseline å¯¹æ¯”')
    parser.add_argument('--task', type=str, default='t2v-A14B', help='ä»»åŠ¡ç±»å‹')
    parser.add_argument('--size', type=str, default='1280*720', choices=list(SIZE_CONFIGS.keys()), help='è§†é¢‘å°ºå¯¸')
    parser.add_argument('--ckpt_dir', type=str, required=True, help='æ¨¡å‹æ£€æŸ¥ç‚¹ç›®å½•')
    parser.add_argument('--frame_num', type=int, default=1, help='å¸§æ•°')
    parser.add_argument('--sample_steps', type=int, default=20, help='é‡‡æ ·æ­¥æ•°')
    parser.add_argument('--prompt', type=str, required=True, help='ç”Ÿæˆæç¤ºè¯')
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­')
    parser.add_argument('--output_dir', type=str, default='comparison_outputs', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--device', type=str, default='cuda', help='è®¾å¤‡')
    parser.add_argument('--cfg_truncate_steps', type=int, default=5, help='CFGæˆªæ–­æ­¥æ•°')
    parser.add_argument('--cfg_truncate_high_noise_steps', type=int, default=3, help='é«˜å™ªå£°CFGæˆªæ–­æ­¥æ•°')
    parser.add_argument('--enable_half_frame_generation', action='store_true', help='å¯ç”¨å¸§æ•°å‡åŠä¼˜åŒ–')
    parser.add_argument('--enable_improved_frame_completion', action='store_true', help='å¯ç”¨æ”¹è¿›çš„å¸§æ•°è¡¥å…¨ï¼ˆå¶æ•°å¸§å¤åˆ¶å‰ä¸€ä¸ªå¥‡æ•°å¸§ï¼‰')
    parser.add_argument('--comparison_mode', type=str, default='cfg_vs_baseline', 
                       choices=['cfg_vs_baseline', 'half_vs_baseline', 'cfg_vs_half', 'improved_vs_baseline'],
                       help='æ¯”è¾ƒæ¨¡å¼')
    
    args = parser.parse_args()
    
    # è§£æå°ºå¯¸
    size = SIZE_CONFIGS[args.size]
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    print("ğŸš€ å¼€å§‹CFGæˆªæ–­æ–¹æ³• vs Baselineå¯¹æ¯”å®éªŒ")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"ğŸ² éšæœºç§å­: {args.seed}")
    
    # åŠ è½½æ¨¡å‹
    model = load_model(args.ckpt_dir, args.device, args.task)
    
    # æ ¹æ®æ¯”è¾ƒæ¨¡å¼ç”Ÿæˆå¯¹åº”çš„ä¸¤ç§æ–¹æ³•
    if args.comparison_mode == 'cfg_vs_baseline':
        # æ–¹æ³•1: CFGæˆªæ–­æ–¹æ³•
        method1_output_dir = os.path.join(args.output_dir, "cfg_truncated")
        result1 = generate_video(
            model=model,
            prompt=args.prompt,
            size=size,
            frame_num=args.frame_num,
            sample_steps=args.sample_steps,
            cfg_truncate_steps=args.cfg_truncate_steps,
            cfg_truncate_high_noise_steps=args.cfg_truncate_high_noise_steps,
            seed=args.seed,
            output_dir=method1_output_dir,
            method_name="CFGæˆªæ–­æ–¹æ³•",
            enable_half_frame_generation=False,
            enable_improved_frame_completion=False
        )
        
        # æ–¹æ³•2: Baseline (æ— æˆªæ–­)
        method2_output_dir = os.path.join(args.output_dir, "baseline")
        result2 = generate_video(
            model=model,
            prompt=args.prompt,
            size=size,
            frame_num=args.frame_num,
            sample_steps=args.sample_steps,
            cfg_truncate_steps=0,
            cfg_truncate_high_noise_steps=0,
            seed=args.seed,
            output_dir=method2_output_dir,
            method_name="Baselineæ–¹æ³•",
            enable_half_frame_generation=False,
            enable_improved_frame_completion=False
        )
        method1_name, method2_name = "CFGæˆªæ–­æ–¹æ³•", "Baselineæ–¹æ³•"
        
    elif args.comparison_mode == 'half_vs_baseline':
        # æ–¹æ³•1: å¸§æ•°å‡åŠä¼˜åŒ–æ–¹æ³•
        method1_output_dir = os.path.join(args.output_dir, "half_frame_optimized")
        result1 = generate_video(
            model=model,
            prompt=args.prompt,
            size=size,
            frame_num=args.frame_num,
            sample_steps=args.sample_steps,
            cfg_truncate_steps=0,
            cfg_truncate_high_noise_steps=0,
            seed=args.seed,
            output_dir=method1_output_dir,
            method_name="å¸§æ•°å‡åŠä¼˜åŒ–æ–¹æ³•",
            enable_half_frame_generation=True,
            enable_improved_frame_completion=False
        )
        
        # æ–¹æ³•2: Baseline (æ— æˆªæ–­)
        method2_output_dir = os.path.join(args.output_dir, "baseline")
        result2 = generate_video(
            model=model,
            prompt=args.prompt,
            size=size,
            frame_num=args.frame_num,
            sample_steps=args.sample_steps,
            cfg_truncate_steps=0,
            cfg_truncate_high_noise_steps=0,
            seed=args.seed,
            output_dir=method2_output_dir,
            method_name="Baselineæ–¹æ³•",
            enable_half_frame_generation=False,
            enable_improved_frame_completion=False
        )
        method1_name, method2_name = "å¸§æ•°å‡åŠä¼˜åŒ–æ–¹æ³•", "Baselineæ–¹æ³•"
        
    elif args.comparison_mode == 'cfg_vs_half':
        # æ–¹æ³•1: CFGæˆªæ–­æ–¹æ³•
        method1_output_dir = os.path.join(args.output_dir, "cfg_truncated")
        result1 = generate_video(
            model=model,
            prompt=args.prompt,
            size=size,
            frame_num=args.frame_num,
            sample_steps=args.sample_steps,
            cfg_truncate_steps=args.cfg_truncate_steps,
            cfg_truncate_high_noise_steps=args.cfg_truncate_high_noise_steps,
            seed=args.seed,
            output_dir=method1_output_dir,
            method_name="CFGæˆªæ–­æ–¹æ³•",
            enable_half_frame_generation=False,
            enable_improved_frame_completion=False
        )
        
        # æ–¹æ³•2: å¸§æ•°å‡åŠä¼˜åŒ–æ–¹æ³•
        method2_output_dir = os.path.join(args.output_dir, "half_frame_optimized")
        result2 = generate_video(
            model=model,
            prompt=args.prompt,
            size=size,
            frame_num=args.frame_num,
            sample_steps=args.sample_steps,
            cfg_truncate_steps=0,
            cfg_truncate_high_noise_steps=0,
            seed=args.seed,
            output_dir=method2_output_dir,
            method_name="å¸§æ•°å‡åŠä¼˜åŒ–æ–¹æ³•",
            enable_half_frame_generation=True,
            enable_improved_frame_completion=False
        )
        method1_name, method2_name = "CFGæˆªæ–­æ–¹æ³•", "å¸§æ•°å‡åŠä¼˜åŒ–æ–¹æ³•"
        
    elif args.comparison_mode == 'improved_vs_baseline':
        # æ–¹æ³•1: æ”¹è¿›å¸§æ•°è¡¥å…¨æ–¹æ³•
        method1_output_dir = os.path.join(args.output_dir, "improved_frame_completion")
        result1 = generate_video(
            model=model,
            prompt=args.prompt,
            size=size,
            frame_num=args.frame_num,
            sample_steps=args.sample_steps,
            cfg_truncate_steps=0,
            cfg_truncate_high_noise_steps=0,
            seed=args.seed,
            output_dir=method1_output_dir,
            method_name="æ”¹è¿›å¸§æ•°è¡¥å…¨æ–¹æ³•",
            enable_half_frame_generation=False,
            enable_improved_frame_completion=True
        )
        
        # æ–¹æ³•2: Baseline (æ— æˆªæ–­)
        method2_output_dir = os.path.join(args.output_dir, "baseline")
        result2 = generate_video(
            model=model,
            prompt=args.prompt,
            size=size,
            frame_num=args.frame_num,
            sample_steps=args.sample_steps,
            cfg_truncate_steps=0,
            cfg_truncate_high_noise_steps=0,
            seed=args.seed,
            output_dir=method2_output_dir,
            method_name="Baselineæ–¹æ³•",
            enable_half_frame_generation=False,
            enable_improved_frame_completion=False
        )
        method1_name, method2_name = "æ”¹è¿›å¸§æ•°è¡¥å…¨æ–¹æ³•", "Baselineæ–¹æ³•"
    
    # è®¡ç®—è¯¯å·®
    print("\n" + "="*80)
    print("ğŸ“Š å¼€å§‹è®¡ç®—è¯¯å·®å¯¹æ¯”...")
    
    error_stats = calculate_error(
        result1, result2, 
        method1_name, method2_name
    )
    print_error_report(error_stats, method1_name, method2_name)
    
    # ä¿å­˜è¯¯å·®ç»Ÿè®¡åˆ°æ–‡ä»¶
    error_file = os.path.join(args.output_dir, "error_comparison.txt")
    with open(error_file, 'w', encoding='utf-8') as f:
        f.write(f"{method1_name} vs {method2_name} è¯¯å·®å¯¹æ¯”åˆ†æ\n")
        f.write("="*50 + "\n\n")
        f.write(f"æ¯”è¾ƒæ¨¡å¼: {args.comparison_mode}\n")
        f.write(f"ç»å¯¹è¯¯å·®å¹³å‡å€¼: {error_stats['absolute_error']['mean']:.6f}\n")
        f.write(f"ç»å¯¹è¯¯å·®æœ€å¤§å€¼: {error_stats['absolute_error']['max']:.6f}\n")
        f.write(f"ç›¸å¯¹è¯¯å·®å¹³å‡å€¼: {error_stats['relative_error']['mean']:.6f}\n")
        f.write(f"ç›¸å¯¹è¯¯å·®æœ€å¤§å€¼: {error_stats['relative_error']['max']:.6f}\n")
        f.write(f"MSE: {error_stats['mse']:.6f}\n")
        f.write(f"PSNR: {error_stats['psnr']:.2f} dB\n")
        f.write(f"SSIM: {error_stats['ssim']:.6f}\n")
    
    print(f"\nğŸ’¾ è¯¯å·®ç»Ÿè®¡å·²ä¿å­˜åˆ°: {error_file}")
    print("ğŸ‰ å¯¹æ¯”å®éªŒå®Œæˆ!")


if __name__ == "__main__":
    main()
