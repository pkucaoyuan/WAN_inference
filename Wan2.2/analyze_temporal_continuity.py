"""
Temporal Continuity Analysis in Latent Space
åˆ†æç”Ÿæˆè¿‡ç¨‹ä¸­ç›¸é‚»å¸§çš„latentè¿ç»­æ€§å˜åŒ–
"""
import os
import sys
import argparse
import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))


def compute_x0_prediction(x_t, eps_pred, alpha_bar_t):
    """
    ä»å™ªå£°latentå’Œé¢„æµ‹å™ªå£°è®¡ç®—x0ä¼°è®¡
    
    xÌ‚â‚€ = (x_t - sqrt(1 - á¾±_t) * Îµ_Î¸) / sqrt(á¾±_t)
    
    Args:
        x_t: å½“å‰å™ªå£°latent [B, F, C, H, W]
        eps_pred: é¢„æµ‹çš„å™ªå£° [B, F, C, H, W]
        alpha_bar_t: ç´¯ç§¯alphaå€¼
    
    Returns:
        x0_pred: x0ä¼°è®¡ [B, F, C, H, W]
    """
    sqrt_alpha_bar = torch.sqrt(alpha_bar_t)
    sqrt_one_minus_alpha_bar = torch.sqrt(1.0 - alpha_bar_t)
    
    # ç¡®ä¿ç»´åº¦æ­£ç¡®
    while len(sqrt_alpha_bar.shape) < len(x_t.shape):
        sqrt_alpha_bar = sqrt_alpha_bar.unsqueeze(-1)
        sqrt_one_minus_alpha_bar = sqrt_one_minus_alpha_bar.unsqueeze(-1)
    
    x0_pred = (x_t - sqrt_one_minus_alpha_bar * eps_pred) / sqrt_alpha_bar
    
    return x0_pred


def compute_mse_distance(latent_f, latent_f_plus_1):
    """
    è®¡ç®—MSEè·ç¦»ï¼ˆå‡æ–¹è¯¯å·®ï¼‰
    
    MSE = mean((xÌ‚â‚€â½á¶ âºÂ¹â¾ - xÌ‚â‚€â½á¶ â¾)Â²)
    
    Args:
        latent_f: å¸§fçš„latent [C, H, W]
        latent_f_plus_1: å¸§f+1çš„latent [C, H, W]
    
    Returns:
        mse: MSEæ ‡é‡
    """
    diff = latent_f_plus_1 - latent_f
    mse = torch.mean(diff ** 2)
    
    return mse.item()


def compute_cosine_similarity(latent_f, latent_f_plus_1):
    """
    è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆæ–¹å‘å‹æŒ‡æ ‡ï¼‰
    
    s = cos(xÌ‚â‚€â½á¶ â¾, xÌ‚â‚€â½á¶ âºÂ¹â¾)
    
    Args:
        latent_f: å¸§fçš„latent [C, H, W]
        latent_f_plus_1: å¸§f+1çš„latent [C, H, W]
    
    Returns:
        similarity: ä½™å¼¦ç›¸ä¼¼åº¦æ ‡é‡
    """
    flat_f = latent_f.flatten()
    flat_f_plus_1 = latent_f_plus_1.flatten()
    
    dot_product = torch.dot(flat_f, flat_f_plus_1)
    norm_f = torch.norm(flat_f, p=2)
    norm_f_plus_1 = torch.norm(flat_f_plus_1, p=2)
    
    similarity = dot_product / (norm_f * norm_f_plus_1 + 1e-8)
    
    return similarity.item()


def analyze_temporal_continuity_single_video(
    prompt: str,
    output_dir: str,
    num_frames: int = 49,
    num_inference_steps: int = 20,
    guidance_scale: float = 7.5,
    seed: int = 42,
    model_path: str = None,
    device: str = "cuda:0",
    use_x0_space: bool = True,
    enable_half_frame: bool = False
):
    """
    åˆ†æå•ä¸ªè§†é¢‘ç”Ÿæˆè¿‡ç¨‹ä¸­çš„æ—¶åºè¿ç»­æ€§
    
    Args:
        prompt: æ–‡æœ¬æç¤º
        output_dir: è¾“å‡ºç›®å½•
        num_frames: å¸§æ•°
        num_inference_steps: æ¨ç†æ­¥æ•°
        guidance_scale: CFGå¼•å¯¼å¼ºåº¦
        seed: éšæœºç§å­
        model_path: æ¨¡å‹è·¯å¾„
        device: è®¾å¤‡
        use_x0_space: Trueä½¿ç”¨x0ç©ºé—´ï¼ŒFalseä½¿ç”¨epsilonç©ºé—´
        enable_half_frame: æ˜¯å¦å¯ç”¨å¸§æ•°å‡åŠ
    """
    import wan
    from omegaconf import OmegaConf
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"{'='*60}")
    print(f"Temporal Continuity Analysis")
    print(f"{'='*60}")
    print(f"Prompt: {prompt}")
    print(f"Frames: {num_frames}")
    print(f"Steps: {num_inference_steps}")
    print(f"Space: {'x0' if use_x0_space else 'epsilon'}")
    print(f"Half-frame: {enable_half_frame}")
    print(f"{'='*60}\n")
    
    # åŠ è½½æ¨¡å‹
    print("Loading model...")
    from wan.configs import WAN_CONFIGS
    
    # ä½¿ç”¨Pythoné…ç½®å¯¹è±¡ï¼ˆä¸generate.pyç›¸åŒçš„æ–¹å¼ï¼‰
    cfg = WAN_CONFIGS['t2v-A14B']
    device_id = int(device.split(':')[1]) if ':' in device else 0
    
    wan_t2v = wan.WanT2V(
        config=cfg,
        checkpoint_dir=model_path,
        device_id=device_id,
        rank=device_id,
        t5_fsdp=False
    )
    
    print("Model loaded.\n")
    
    # å­˜å‚¨æ¯æ­¥çš„æŒ‡æ ‡
    step_indices = []
    timesteps_list = []
    normalized_l2_distances = []  # æ¯æ­¥çš„å¹³å‡å½’ä¸€åŒ–L2è·ç¦»
    cosine_similarities = []  # æ¯æ­¥çš„å¹³å‡ä½™å¼¦ç›¸ä¼¼åº¦
    
    # Hookå‡½æ•°ï¼šæ•è·æ¯æ­¥çš„latentå’Œé¢„æµ‹
    step_data = {'step': 0}
    
    def capture_step_hook(module, input_data, output_data):
        """æ•è·æ¯æ­¥çš„x_tå’Œeps_pred"""
        # è¿™ä¸ªhookéœ€è¦æ ¹æ®å®é™…çš„æ¨¡å‹ç»“æ„è°ƒæ•´
        # æš‚æ—¶ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
        pass
    
    # ç”±äºç›´æ¥hookæ¯”è¾ƒå¤æ‚ï¼Œæˆ‘ä»¬ä¿®æ”¹generateå‡½æ•°æ¥è®°å½•æ•°æ®
    # è¿™é‡Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªä¿®æ”¹ç‰ˆçš„ç”Ÿæˆå‡½æ•°
    
    print("Generating video with continuity tracking...")
    
    # è°ƒç”¨generateå¹¶è®°å½•ä¸­é—´ç»“æœ
    # æ³¨æ„ï¼šéœ€è¦ä¿®æ”¹wan.text2video.pyæ¥æ”¯æŒè¿”å›ä¸­é—´latent
    # è¿™é‡Œæˆ‘ä»¬å‡è®¾å·²ç»ä¿®æ”¹ï¼Œæˆ–è€…ä½¿ç”¨è°ƒè¯•æ¨¡å¼
    
    video, timing_info = wan_t2v.generate(
        input_prompt=prompt,
        size=(832, 480),
        frame_num=num_frames,
        shift=12.0,
        sample_solver='unipc',
        sampling_steps=num_inference_steps,
        guide_scale=guidance_scale,
        n_prompt="",
        seed=seed,
        offload_model=True,
        cfg_truncate_steps=0,  # ç¦ç”¨CFGæˆªæ–­
        cfg_truncate_high_noise_steps=0,  # ç¦ç”¨é«˜å™ªå£°CFGæˆªæ–­
        enable_half_frame_generation=enable_half_frame,
        enable_debug=True,  # å¯ç”¨è°ƒè¯•æ¨¡å¼ä»¥è·å–ä¸­é—´ç»“æœ
        debug_output_dir=output_dir
    )
    
    print(f"\nğŸ“‹ åˆ†æè¯´æ˜:")
    print(f"   å°†åˆ†ææ¯æ­¥ä¼ é€’çš„å®é™…latent (x_t)")
    print(f"   è€Œä¸æ˜¯ä¸­é—´çš„x0é¢„æµ‹")
    print(f"   x_tæ˜¯çœŸæ­£å½±å“ä¸‹ä¸€æ­¥çš„é‡")
    
    print("\nâœ… Video generation completed.")
    
    # è¯»å–å¹¶åˆ†æä¿å­˜çš„latent
    debug_latents_dir = os.path.join(output_dir, "debug_latents")
    if os.path.exists(debug_latents_dir):
        print(f"\nğŸ“Š åˆ†æä¿å­˜çš„latents...")
        print(f"   Latentsç›®å½•: {debug_latents_dir}")
        analyze_saved_latents(debug_latents_dir, output_dir, use_x0_space)
    else:
        print(f"\nâš ï¸  æœªæ‰¾åˆ°debug latentsç›®å½•: {debug_latents_dir}")
        print("    è¯·ç¡®ä¿enable_debug=True")
        print("    Latentsä¼šè‡ªåŠ¨ä¿å­˜åˆ°: {output_dir}/debug_latents/")


def analyze_saved_latents(debug_dir: str, output_dir: str, use_x0_space: bool = True):
    """
    åˆ†æä¿å­˜çš„latentæ–‡ä»¶
    
    Args:
        debug_dir: åŒ…å«ä¿å­˜çš„latentçš„ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        use_x0_space: ä½¿ç”¨x0ç©ºé—´è¿˜æ˜¯epsilonç©ºé—´
    """
    # æŸ¥æ‰¾æ‰€æœ‰ä¿å­˜çš„latentæ–‡ä»¶
    latent_files = sorted([f for f in os.listdir(debug_dir) if f.startswith('latent_step_')])
    
    if not latent_files:
        print("No latent files found.")
        return
    
    print(f"Found {len(latent_files)} latent files.")
    
    step_indices = []
    normalized_l2_distances = []
    cosine_similarities = []
    
    # æ‰“å°ç¬¬ä¸€ä¸ªæ–‡ä»¶çš„ä¿¡æ¯ç”¨äºè°ƒè¯•
    first_file_path = os.path.join(debug_dir, latent_files[0])
    first_data = torch.load(first_file_path)
    print(f"\nğŸ“‹ Latentæ–‡ä»¶æ ¼å¼:")
    print(f"   Keys: {list(first_data.keys())}")
    print(f"   x0_pred shape: {first_data['x0_pred'].shape}")
    print(f"   eps_pred shape: {first_data['eps_pred'].shape}")
    print(f"   ä½¿ç”¨ç©ºé—´: {'x0' if use_x0_space else 'epsilon'}")
    
    # æ£€æŸ¥latentçš„ç»´åº¦é¡ºåº
    test_latent = first_data['x_t']  # ä½¿ç”¨x_tè€Œä¸æ˜¯x0_pred
    print(f"   x_t shape: {first_data['x_t'].shape}")
    print(f"   åˆ†æå¯¹è±¡: x_t (å®é™…ä¼ é€’çš„å™ªå£°latent)")
    print(f"   æµ‹è¯•latent shape: {test_latent.shape}")
    print(f"   æµ‹è¯•latentç»´åº¦: {test_latent.dim()}")
    if test_latent.dim() == 5:
        print(f"   å‡è®¾ç»´åº¦é¡ºåº: [Batch, Channel, Frame, Height, Width]")
    elif test_latent.dim() == 4:
        print(f"   å‡è®¾ç»´åº¦é¡ºåº: [Channel, Frame, Height, Width]")
    print()
    
    for latent_file in tqdm(latent_files, desc="Analyzing latents"):
        # åŠ è½½latent
        latent_path = os.path.join(debug_dir, latent_file)
        data = torch.load(latent_path)
        
        step = data['step']
        # ä½¿ç”¨x_tï¼ˆå®é™…ä¼ é€’çš„latentï¼‰ï¼Œè€Œä¸æ˜¯x0_predï¼ˆä¸­é—´ä¼°è®¡ï¼‰
        latent = data['x_t']
        
        # å¤„ç†ç»´åº¦ï¼šWANæ ¼å¼æ˜¯ [B, C, F, H, W] æˆ– [C, F, H, W]
        if latent.dim() == 5:
            # [B, C, F, H, W]ï¼Œå–ç¬¬ä¸€ä¸ªbatch
            B, C, F, H, W = latent.shape
            latent = latent[0]  # ç°åœ¨æ˜¯ [C, F, H, W]
        elif latent.dim() == 4:
            # [C, F, H, W]
            C, F, H, W = latent.shape
        else:
            print(f"âš ï¸  Unexpected latent shape: {latent.shape}")
            continue
        
        if F < 2:
            if step == 1:
                print(f"âš ï¸  Step {step}: åªæœ‰{F}å¸§ï¼Œæ— æ³•è®¡ç®—ç›¸é‚»å¸§è¿ç»­æ€§")
            continue  # éœ€è¦è‡³å°‘2å¸§
        
        # è®¡ç®—ç›¸é‚»å¸§çš„æŒ‡æ ‡ï¼ˆæ³¨æ„ï¼šè¿™æ˜¯åˆ†ææ¯æ­¥å†…çš„ç›¸é‚»å¸§ï¼Œä¸æ˜¯ç›¸é‚»æ­¥éª¤ï¼‰
        mse_distances = []
        cos_similarities = []
        
        # ç¬¬ä¸€æ­¥æ—¶æ‰“å°è¯¦ç»†ä¿¡æ¯
        if step == 1:
            print(f"\nğŸ” Step {step} è¯¦ç»†ä¿¡æ¯:")
            print(f"   Latent shape after processing: [C={C}, F={F}, H={H}, W={W}]")
            print(f"   å°†åˆ†æ {F-1} å¯¹ç›¸é‚»å¸§")
            print(f"   å¸§0 vs å¸§1, å¸§1 vs å¸§2, ..., å¸§{F-2} vs å¸§{F-1}")
        
        for f in range(F - 1):
            latent_f = latent[:, f, :, :]  # [C, H, W]
            latent_f_plus_1 = latent[:, f + 1, :, :]  # [C, H, W]
            
            # ç¬¬ä¸€æ­¥æ—¶æ‰“å°å‰ä¸¤å¯¹å¸§çš„è¯¦ç»†ä¿¡æ¯
            if step == 1 and f < 2:
                print(f"\n   å¸§{f} vs å¸§{f+1}:")
                print(f"     å¸§{f} èŒƒå›´: [{latent_f.min():.4f}, {latent_f.max():.4f}]")
                print(f"     å¸§{f+1} èŒƒå›´: [{latent_f_plus_1.min():.4f}, {latent_f_plus_1.max():.4f}]")
                print(f"     å¸§{f} å‡å€¼: {latent_f.mean():.4f}, æ ‡å‡†å·®: {latent_f.std():.4f}")
                print(f"     å¸§{f+1} å‡å€¼: {latent_f_plus_1.mean():.4f}, æ ‡å‡†å·®: {latent_f_plus_1.std():.4f}")
            
            # è®¡ç®—MSEè·ç¦»
            mse_dist = compute_mse_distance(latent_f, latent_f_plus_1)
            mse_distances.append(mse_dist)
            
            # ç¬¬ä¸€æ­¥æ—¶æ‰“å°è®¡ç®—ç»“æœ
            if step == 1 and f < 2:
                print(f"     MSEè·ç¦»: {mse_dist:.6f}")
            
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            cos_sim = compute_cosine_similarity(latent_f, latent_f_plus_1)
            cos_similarities.append(cos_sim)
            
            # ç¬¬ä¸€æ­¥æ—¶æ‰“å°è®¡ç®—ç»“æœ
            if step == 1 and f < 2:
                print(f"     ä½™å¼¦ç›¸ä¼¼åº¦: {cos_sim:.6f}")
        
        # å–å¹³å‡
        avg_mse = np.mean(mse_distances)
        avg_cos = np.mean(cos_similarities)
        
        step_indices.append(step)
        normalized_l2_distances.append(avg_mse)  # å¤ç”¨å˜é‡åï¼Œå®é™…å­˜MSE
        cosine_similarities.append(avg_cos)
    
    # ç»˜å›¾ï¼ˆæ³¨æ„ï¼šnormalized_l2_distanceså˜é‡å®é™…å­˜å‚¨çš„æ˜¯mse_distancesï¼‰
    plot_continuity_metrics(
        step_indices,
        normalized_l2_distances,  # å®é™…æ˜¯mse_distances
        cosine_similarities,
        output_dir,
        use_x0_space
    )


def plot_continuity_metrics(
    steps: list,
    mse_distances: list,
    cosine_sims: list,
    output_dir: str,
    use_x0_space: bool
):
    """
    ç»˜åˆ¶æ—¶åºè¿ç»­æ€§æŒ‡æ ‡
    
    Args:
        steps: æ­¥æ•°åˆ—è¡¨
        mse_distances: MSEè·ç¦»åˆ—è¡¨
        cosine_sims: ä½™å¼¦ç›¸ä¼¼åº¦åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
        use_x0_space: æ˜¯å¦ä½¿ç”¨x0ç©ºé—´
    """
    space_name = "x_t (Noisy Latent)"
    
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
    
    # å­å›¾1: MSEè·ç¦»
    ax1.plot(steps, mse_distances, 'b-o', linewidth=2.5, markersize=6, label=f'MSE Distance')
    ax1.set_xlabel('Denoising Step', fontsize=13)
    ax1.set_ylabel('MSE', fontsize=13)
    ax1.set_title(f'Temporal Continuity: MSE Between Adjacent Frames in {space_name}', 
                  fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3, linestyle='--')
    ax1.legend(loc='best', fontsize=11)
    
    # æ·»åŠ è¯´æ˜æ–‡å­—
    ax1.text(0.02, 0.98, 'Lower = More Similar', 
             transform=ax1.transAxes, fontsize=10, verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))
    
    # å­å›¾2: ä½™å¼¦ç›¸ä¼¼åº¦
    ax2.plot(steps, cosine_sims, 'r-s', linewidth=2.5, markersize=6, label=f'Cosine Similarity')
    ax2.set_xlabel('Denoising Step', fontsize=13)
    ax2.set_ylabel('Similarity', fontsize=13)
    ax2.set_title(f'Temporal Continuity: Cosine Similarity in {space_name}', 
                  fontsize=14, fontweight='bold')
    ax2.grid(True, alpha=0.3, linestyle='--')
    ax2.legend(loc='best', fontsize=11)
    ax2.set_ylim([-0.1, 1.05])  # å…è®¸è´Ÿå€¼ï¼Œå› ä¸ºæ—©æœŸå¯èƒ½æ˜¯è´Ÿç›¸å…³
    
    # æ·»åŠ è¯´æ˜æ–‡å­—
    ax2.text(0.02, 0.02, 'Higher = More Similar', 
             transform=ax2.transAxes, fontsize=10, verticalalignment='bottom',
             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    output_path = os.path.join(output_dir, "temporal_continuity_x_t.png")
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"\nâœ… Continuity plot saved to: {output_path}")
    
    # ä¿å­˜æ•°æ®
    data_path = os.path.join(output_dir, "temporal_continuity_data_x_t.npz")
    np.savez(data_path, 
             steps=steps, 
             mse_distances=mse_distances, 
             cosine_similarities=cosine_sims)
    print(f"âœ… Data saved to: {data_path}")
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"\n{'='*60}")
    print(f"Temporal Continuity Statistics (x_t - Noisy Latent)")
    print(f"{'='*60}")
    print(f"MSE Between Adjacent Frames:")
    print(f"  Mean: {np.mean(mse_distances):.6f}")
    print(f"  Std:  {np.std(mse_distances):.6f}")
    print(f"  Min:  {np.min(mse_distances):.6f} (step {steps[np.argmin(mse_distances)]})")
    print(f"  Max:  {np.max(mse_distances):.6f} (step {steps[np.argmax(mse_distances)]})")
    print(f"\nCosine Similarity:")
    print(f"  Mean: {np.mean(cosine_sims):.6f}")
    print(f"  Std:  {np.std(cosine_sims):.6f}")
    print(f"  Min:  {np.min(cosine_sims):.6f} (step {steps[np.argmin(cosine_sims)]})")
    print(f"  Max:  {np.max(cosine_sims):.6f} (step {steps[np.argmax(cosine_sims)]})")
    print(f"\nğŸ“‹ è¯´æ˜:")
    print(f"  - åˆ†æçš„æ˜¯æ¯æ­¥å®é™…ä¼ é€’çš„å™ªå£°latent (x_t)")
    print(f"  - x_tæ˜¯çœŸæ­£å½±å“ä¸‹ä¸€æ­¥è®¡ç®—çš„é‡")
    print(f"  - é¢„æœŸè¶‹åŠ¿: MSEä»é«˜åˆ°ä½, ä½™å¼¦ç›¸ä¼¼åº¦ä»ä½åˆ°é«˜")
    print(f"{'='*60}\n")


def create_demo_plot():
    """
    åˆ›å»ºä¸€ä¸ªæ¼”ç¤ºå›¾è¡¨ï¼ˆä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼‰
    ç”¨äºå±•ç¤ºåˆ†æç»“æœçš„æ ¼å¼
    """
    print("Creating demo plot with simulated data...")
    
    # æ¨¡æ‹Ÿæ•°æ®ï¼šæ—©æœŸæ­¥éª¤ç›¸é‚»å¸§å·®å¼‚å¤§ï¼ŒåæœŸè¶‹äºç¨³å®š
    steps = list(range(1, 21))
    
    # MSEè·ç¦»ï¼šæ—©æœŸé«˜ï¼ˆä¸è¿ç»­ï¼‰ï¼ŒåæœŸä½ï¼ˆè¿ç»­ï¼‰
    mse_distances = [
        0.25, 0.20, 0.17, 0.14, 0.11,
        0.08, 0.06, 0.04, 0.03, 0.02,
        0.012, 0.008, 0.005, 0.004, 0.003,
        0.002, 0.001, 0.001, 0.0005, 0.0005
    ]
    
    # ä½™å¼¦ç›¸ä¼¼åº¦ï¼šæ—©æœŸä½ï¼ŒåæœŸé«˜ï¼ˆè¶‹è¿‘1ï¼‰
    cosine_sims = [
        0.65, 0.70, 0.74, 0.78, 0.82,
        0.85, 0.88, 0.90, 0.92, 0.94,
        0.95, 0.96, 0.97, 0.975, 0.98,
        0.985, 0.988, 0.990, 0.992, 0.994
    ]
    
    output_dir = "./demo_continuity_analysis"
    os.makedirs(output_dir, exist_ok=True)
    
    plot_continuity_metrics(steps, mse_distances, cosine_sims, output_dir, use_x0_space=True)
    
    print(f"\nâœ… Demo plot created in: {output_dir}")
    print("This demonstrates the expected pattern:")
    print("  - Early steps: High MSE, low cosine similarity (frames differ)")
    print("  - Later steps: Low MSE, high cosine similarity (frames converge)")


def main():
    parser = argparse.ArgumentParser(description="Temporal Continuity Analysis in Latent Space")
    
    parser.add_argument("--prompt", type=str, 
                        default="A young woman in a red jacket is walking across a busy crosswalk in a modern city at night.",
                        help="Text prompt for generation")
    parser.add_argument("--output_dir", type=str, default="./continuity_analysis",
                        help="Output directory")
    parser.add_argument("--num_frames", type=int, default=49,
                        help="Number of frames")
    parser.add_argument("--num_inference_steps", type=int, default=20,
                        help="Number of inference steps")
    parser.add_argument("--guidance_scale", type=float, default=7.5,
                        help="CFG guidance scale")
    parser.add_argument("--seed", type=int, default=42,
                        help="Random seed")
    parser.add_argument("--model_path", type=str, default=None,
                        help="Model checkpoint directory")
    parser.add_argument("--device", type=str, default="cuda:0",
                        help="Device")
    parser.add_argument("--use_epsilon", action="store_true",
                        help="Use epsilon space instead of x0 space")
    parser.add_argument("--enable_half_frame", action="store_true",
                        help="Enable half-frame generation")
    parser.add_argument("--demo", action="store_true",
                        help="Create demo plot with simulated data")
    
    args = parser.parse_args()
    
    if args.demo:
        create_demo_plot()
    else:
        if args.model_path is None:
            print("Error: --model_path is required (unless using --demo)")
            return
        
        analyze_temporal_continuity_single_video(
            prompt=args.prompt,
            output_dir=args.output_dir,
            num_frames=args.num_frames,
            num_inference_steps=args.num_inference_steps,
            guidance_scale=args.guidance_scale,
            seed=args.seed,
            model_path=args.model_path,
            device=args.device,
            use_x0_space=not args.use_epsilon,
            enable_half_frame=args.enable_half_frame
        )


if __name__ == "__main__":
    main()

