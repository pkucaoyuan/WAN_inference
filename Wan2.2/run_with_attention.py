#!/usr/bin/env python3
# Copyright 2024-2025 The Alibaba Wan Team Authors. All rights reserved.
"""
å‘½ä»¤è¡Œå·¥å…·ï¼šé€šè¿‡å‚æ•°æ§åˆ¶æ³¨æ„åŠ›å¯è§†åŒ–
"""

import argparse
import torch
from wan.text2video import WanT2V


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="WANæ¨¡å‹è§†é¢‘ç”Ÿæˆ - æ”¯æŒæ³¨æ„åŠ›å¯è§†åŒ–æ§åˆ¶")
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument("--prompt", type=str, required=True, help="è¾“å…¥æç¤ºè¯")
    parser.add_argument("--frames", type=int, default=16, help="è§†é¢‘å¸§æ•°")
    parser.add_argument("--width", type=int, default=256, help="è§†é¢‘å®½åº¦")
    parser.add_argument("--height", type=int, default=256, help="è§†é¢‘é«˜åº¦")
    parser.add_argument("--steps", type=int, default=25, help="å»å™ªæ­¥æ•°")
    parser.add_argument("--guidance", type=float, default=7.5, help="CFGå¼•å¯¼å°ºåº¦")
    
    # æ³¨æ„åŠ›å¯è§†åŒ–å‚æ•°
    parser.add_argument("--enable-attention", action="store_true", 
                       help="å¯ç”¨æ³¨æ„åŠ›å¯è§†åŒ–")
    parser.add_argument("--attention-dir", type=str, default="attention_outputs",
                       help="æ³¨æ„åŠ›å¯è§†åŒ–è¾“å‡ºç›®å½•")
    
    # å…¶ä»–å‚æ•°
    parser.add_argument("--seed", type=int, default=-1, help="éšæœºç§å­")
    parser.add_argument("--output-dir", type=str, help="è§†é¢‘è¾“å‡ºç›®å½•")
    
    args = parser.parse_args()
    
    print("=== WANæ¨¡å‹è§†é¢‘ç”Ÿæˆ ===")
    print(f"ğŸ“ æç¤ºè¯: {args.prompt}")
    print(f"ğŸ¬ å¸§æ•°: {args.frames}")
    print(f"ğŸ“ å°ºå¯¸: {args.width}x{args.height}")
    print(f"ğŸ”„ æ­¥æ•°: {args.steps}")
    print(f"ğŸ¯ å¼•å¯¼å°ºåº¦: {args.guidance}")
    print(f"ğŸ” æ³¨æ„åŠ›å¯è§†åŒ–: {'å¯ç”¨' if args.enable_attention else 'ç¦ç”¨'}")
    if args.enable_attention:
        print(f"ğŸ“ æ³¨æ„åŠ›è¾“å‡ºç›®å½•: {args.attention_dir}")
    print()
    
    # åˆå§‹åŒ–æ¨¡å‹
    print("æ­£åœ¨åŠ è½½WANæ¨¡å‹...")
    try:
        model = WanT2V.from_pretrained(
            "pkucaoyuan/WAN2.2_T2V_A14B",
            torch_dtype=torch.bfloat16,
            device_map="auto"
        )
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ\n")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # ç”Ÿæˆè§†é¢‘
    try:
        video, timing_info = model.generate(
            input_prompt=args.prompt,
            frame_num=args.frames,
            size=(args.width, args.height),
            sampling_steps=args.steps,
            guide_scale=args.guidance,
            seed=args.seed,
            enable_attention_visualization=args.enable_attention,
            attention_output_dir=args.attention_dir
        )
        
        print("âœ… è§†é¢‘ç”Ÿæˆå®Œæˆ!")
        print(f"   è§†é¢‘å½¢çŠ¶: {video.shape}")
        print(f"   ç”Ÿæˆæ—¶é—´: {timing_info}")
        
        if args.enable_attention:
            print(f"   æ³¨æ„åŠ›å¯è§†åŒ–å·²ä¿å­˜åˆ°: {args.attention_dir}/")
            print("   ç”Ÿæˆæ–‡ä»¶:")
            print("   - average_cross_attention_map.png")
            print("   - attention_analysis_report.md")
        else:
            print("   æ³¨æ„: æœªå¯ç”¨æ³¨æ„åŠ›å¯è§†åŒ–")
            
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
